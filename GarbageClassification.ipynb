{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO9Na62J9qLLNoMNxmmMqo1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Talha-Bicak/GarbageClassification/blob/main/GarbageClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imutils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNFAb0_C9Ee6",
        "outputId": "32365979-787a-4110-ce89-b86ccc4f2fb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imutils in /usr/local/lib/python3.10/dist-packages (0.5.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gL8MDINf9Nph",
        "outputId": "f5f937ec-b45a-433b-b0d0-b7ae9fee4417"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.23.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMbi28yrnaMU"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import urllib\n",
        "import itertools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import random , os , glob\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import shuffle\n",
        "from urllib.request import urlopen\n",
        "\n",
        "#Warningleri kapatmak için kullanılmaktadır.\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#Model değerlendirme için kullanılacak olan kütüphaneler\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Model için kullanılacak olan kütüphaneler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, MaxPool2D, Dense, Dropout, SpatialDropout2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img, array_to_img"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2t-w67w2nsvs",
        "outputId": "1ce5836c-8820-4cee-bb66-0c516c787edb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir_path = '/content/drive/MyDrive/GarbageClassification/Garbage classification'"
      ],
      "metadata": {
        "id": "UQOc_LaN5GZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Target_Size ve Label Değerlerinin Belirlenmesi\n",
        "\n",
        "target_size = (224, 224)\n",
        "\n",
        "waste_labels = {\"cardboard\": 0,\n",
        "                \"glass\": 1,\n",
        "                \"metal\" : 2,\n",
        "                \"paper\" : 3,\n",
        "                \"plastic\" : 4,\n",
        "                \"trash\" : 5}"
      ],
      "metadata": {
        "id": "3EMpRorJ5iNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_datasets(path):\n",
        "    \"\"\"\n",
        "Görsellerin bulunduğu dizindeki görüntüyü okuyup etiketlerini oluşturur.\n",
        "Parametreler:\n",
        "path: Görsellerin bulunduğu dizini ifade eder.\n",
        "Return:\n",
        "x: Görüntülere ait matris bilgilerini tutar.\n",
        "labels: Görüntünün ait olduğu sınıf bilgisini tutan liste.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    x = []\n",
        "    labels = []\n",
        "\n",
        "    # Gönderdiğimiz pathdeki görüntüleri listeleyip sıralamaktadır.\n",
        "    image_paths = sorted(list(paths.list_images(path)))\n",
        "\n",
        "    for image_path in image_paths:\n",
        "        # Belirtilen pathdeki görüntüler openCV kütüphanesi ile okunmaktadır.\n",
        "        img = cv2.imread(image_path)\n",
        "\n",
        "        # Okunan görüntüler başlangıçta belirlenen target_size'a göre yeniden ölçeklendirilir.\n",
        "        img = cv2.resize(img, target_size)\n",
        "\n",
        "        # Ölçeklendirilen görüntüler x listesine eklenir.\n",
        "        x.append(img)\n",
        "\n",
        "        # Her bir path \"/\" ifadesi ile ayrıldığında dönen listenin sonran ikinci elamanı label'ı temsil etmektedir.\n",
        "        label = image_path.split(os.path.sep)[-2]\n",
        "\n",
        "        # Yakalanan labelların sayısal değer karşılıklarının olduğu waste_labels sözlüğü içerisinden gönderilen key\n",
        "        # değerine karşılık value değeri alınarak label oluşturulur.\n",
        "        labels.append(waste_labels[label])\n",
        "\n",
        "    # Veri seti random bir şekilde karıştırılır.\n",
        "    x, labels = shuffle(x, labels, random_state=42)\n",
        "\n",
        "    # Boyut ve Sınıf bilgisi raporlanmaktadır.\n",
        "    print(f\"X boyutu: {np.array(x).shape}\")\n",
        "    print(f\"Label sınıf sayısı: {len(np.unique(labels))} Gözlem sayısı: {len(labels)}\")\n",
        "\n",
        "    return x, labels"
      ],
      "metadata": {
        "id": "NIHTnsMy5w-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, labes = load_datasets(dir_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "tpw4iZ949Dab",
        "outputId": "4897c1b4-b43b-48da-ebcb-bc077057f1a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-eb3bcf048073>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-8be6775810fb>\u001b[0m in \u001b[0;36mload_datasets\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimage_paths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# Belirtilen pathdeki görüntüler openCV kütüphanesi ile okunmaktadır.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# Okunan görüntüler başlangıçta belirlenen target_size'a göre yeniden ölçeklendirilir.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (cv2.imread(dir_path)).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "tL_R2sWc2lG-",
        "outputId": "5ba98250-dbfc-4940-99a8-7a14a554df36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-707fbe4ae75e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_img(image_batch, label_batch):\n",
        "\"\"\"\n",
        "\n",
        "Veri seti içerisinden görüntü görselleştirir.\n",
        "\n",
        "Parametreler:\n",
        "\n",
        "image_batch: Görüntülere ait matris bilgilerini tutar.\n",
        "\n",
        "label_batch: Görüntünün ait olduğu sınıf bilgisini tutan liste.\n",
        "\"\"\"\n",
        "  plt.figure(figsize=(10,10))\n",
        "  for n in range(10):\n",
        "    ax = plt.subplot(5,5,n+1)\n",
        "    plt.imshow(image_batch[n])\n",
        "    plt.title(np.array(list(waste_labels.keys()))[to_categorical(labels, num_classes=6)[n]==1][0].title())\n",
        "    plt.axis('off')"
      ],
      "metadata": {
        "id": "teOhK_yvB15d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train veri seti için bir generator tanımlayalım.\n",
        "train = ImageDataGenerator(horizontal_flip = True, #Görüntüleri rastgele yatay olarak çevirmektedir.\n",
        "                           vertical_flip = True,   #Görüntüleri rastgele dikey olarak çevirmektedir.\n",
        "                           validation_split = 0.1, #Test veri setinin oranı\n",
        "                           rescale = 1./255,       #Görüntüleri yeniden ölçeklendirme işlemi yapar.Buradaki oran verileri 0-1 arasına dönüştürür.\n",
        "                           shear_range = 0.1,      #Görüntülere eğim vererek saat yönünün tersine yeni veriler üretmemizi sağlar.\n",
        "                           zoom_range = 0.1,\n",
        "                           width_shift_range = 0.1,#Genişlik kaydırma için kullanılır.\n",
        "                           height_shift_range = 0.1)#Uzunluk kaydırma işlemi için kullanılır.\n",
        "\n",
        "# Test veri seti için bir generator tanımlayalım.\n",
        "test = ImageDataGenerator(rescale= 1/255,\n",
        "                          validation_split = 0.1)"
      ],
      "metadata": {
        "id": "AEM22hp3__s9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train.flow_from_directory(directory=dir_path,         #Veri Setimizin bulunduğu dizin.\n",
        "                                            target_size= (target_size), #Görüntülerin boyut bilgisini içerir.\n",
        "                                            class_mode = \"categorical\", #\n",
        "                                            subset = 'training')\n",
        "test_genertor = test.flow_from_directory(directory= dir_path,\n",
        "                                         target_size= (target_size),\n",
        "                                         batch_size=251,               #Verilerin boyutunu ifade eder.\n",
        "                                         class_mode = 'categorical',   #İkiden fazla kategoride veri bulunduğu zaman kullanılır.Eğerki iki farklı verimiz olsaydı 'binary' kullanıcaktık.\n",
        "                                         subset= 'validation')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJCzvVZwfyk6",
        "outputId": "82cd596c-0681-478c-91d1-da5b00d485a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2275 images belonging to 1 classes.\n",
            "Found 252 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(filters=32,                #Evrişim Ağında kullanılacak filtre sayısı\n",
        "                 kernel_size=(3,3),         #Filtrenin boyutu\n",
        "                 padding='same',            #Giriş matriksi ile çıkış matrisi aynı boyutta olmadığından eksik olan pixelleri 0 ile doldurur.Bunun farklı yolları da vardır.\n",
        "                 input_shape=(224,224,3), #Giriş görüntülerinin boyut bilgisi\n",
        "                 activation = 'relu'))      #Bu katmandan diğer katmana geçiş için kullanılacak olan aktivasyon fonksiyonu\n",
        "model.add(MaxPool2D(pool_size=2,strides=(2,2)))\n",
        "# Bu katmana pooling katmanı denir.Görüntünün özelliklerini kaybetmeden boyutunun küçültülmesine yarar.Maxpooling ise uygulanan filtre içerisindeki e yüksek değerleri alıp sonuç matriksini oluşturmaya yarar.\n",
        "\n",
        "model.add(Conv2D(filters=64,kernel_size=(3,3),padding='same',activation = 'relu'))\n",
        "model.add(MaxPool2D(pool_size=2,strides=(2,2)))\n",
        "\n",
        "model.add(Conv2D(filters=32,kernel_size=(3,3),padding='same',activation = 'relu'))\n",
        "model.add(MaxPool2D(pool_size=2,strides=(2,2)))\n",
        "\n",
        "model.add(Flatten()) # Önceki katmanlardan gelen verileri düzleştirme işlemi yapar. Yani 3D boyutlu veya 2D boyutlu verileri 1D boyutuna indirgeyerek bir sonraki katmanda kullanılmak üzere düzenler.\n",
        "\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "model.add(Dropout(rate=0.2))\n",
        "\n",
        "model.add(Dense(units= 32, activation='relu'))\n",
        "model.add(Dropout(rate=0.2))\n",
        "\n",
        "model.add(Dense(units=6, activation='softmax'))"
      ],
      "metadata": {
        "id": "5cuUtDqcjokX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "LY7-qNH-q7Zl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e1ebbd9-1164-4297-80d2-3097c4a72194"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 224, 224, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 112, 112, 32)      0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 112, 112, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 56, 56, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 56, 56, 32)        18464     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 28, 28, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                1605696   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 198       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1645830 (6.28 MB)\n",
            "Trainable params: 1645830 (6.28 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Optimizasonu"
      ],
      "metadata": {
        "id": "_0r1uj0vPWEH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',  #Optimizasyon için kullanılacak olan kayıp fonksiyonu\n",
        "              optimizer = 'adam',   #Optimize işleminde kullanılacak olan yöntem\n",
        "              metrics = [tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), \"acc\"]) #Başarının nasıl değerlendirileceğinin metrikleri\n",
        "#Aşırı öğtenmenin karşısına geçme"
      ],
      "metadata": {
        "id": "c_PTAZ2zIWSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aşırı Öğrenmenin Önüne geçme"
      ],
      "metadata": {
        "id": "76UqramyPaKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "callback = [EarlyStopping(monitor = 'val_loss', #Hangi metrik açısından takip edileceğini belirlenmesi(burada validation_loss kullanıldı)\n",
        "                          patience = 50, #Kaç adımdan sonra hala ilerleme yoksa durdurma bilgisi girilir\n",
        "                          verbose = 1, # 0=ekranda hiç bir sonuç verilmez. 1 = Anlık olarak ilerleme barı  2 = Her epochs sonucunda bilgilendirme yapar.\n",
        "                          mode =  \"min\"),\n",
        "            ModelCheckpoint(filepath = 'mymodel.h5', #İlgili dosyanın ne şekilde kaydedileceği belirtilir.\n",
        "                            monitor = 'val_loss',\n",
        "                            mode = 'min',\n",
        "                            save_best_only= True, #Sadece en iyi modeli kaydetme\n",
        "                            save_weights_only=False)] #Sadece ağırlıkları kaydet"
      ],
      "metadata": {
        "id": "1BzG-5wYLofh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit_generator(generator = train_generator, #Eğitim veri setini giriyoruz.\n",
        "                    epochs=100, #Verinin kaç öğrenme sürecinden geçeceğini belirlenir.\n",
        "                    validation_data = test_generator #Valide edilecek veri setini\n",
        "                    callbacks = callbacks #Model eğitme sürecinde modelin aşırı öğrenmesinin önüne geçmek amacıyla yapılan bilgilendirme\n",
        "                    workers=4, #?\n",
        "                    steps_per_epoch = 2276//32, #?\n",
        "                    validation_steps = 251//32 #?\n",
        "                    )"
      ],
      "metadata": {
        "id": "Yjz0ESiyTmAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------\n",
        "# Accuracy Grafiği\n",
        "#------------------\n",
        "\n",
        "plt.figure(figsize=(20, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['acc'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_acc'], label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.xlabel('Epoch', fontsize=16)\n",
        "plt.ylabel('Accuracy', fontsize=16)\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy', fontsize=16)\n",
        "\n",
        "#--------------\n",
        "# Loss Grafiği\n",
        "#--------------\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.xlabel('Epoch', fontsize=16)\n",
        "plt.ylabel('Loss', fontsize=16)\n",
        "plt.ylim([0,max(plt.ylim())])\n",
        "plt.title('Training and Validation Loss', fontsize=16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "L5HlaaTaC-Je"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, precision, recall, acc = model.evaluate(test_generator, batch_size=32)"
      ],
      "metadata": {
        "id": "0QgzyBDtDdT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nTest accuracy: %.1f%%\" % (100.0 * acc))\n",
        "print(\"\\nTest loss: %.1f%%\" % (100.0 * loss))\n",
        "print(\"\\nTest precision: %.1f%%\" % (100.0 * precision))\n",
        "print(\"\\nTest recall: %.1f%%\" % (100.0 * recall))"
      ],
      "metadata": {
        "id": "PZV_gu00D68U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clasification Report\n",
        "\n",
        "x_test, y_test = test.generator.next()\n",
        "\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "y_test= np.argmax(y_test, axis=1)"
      ],
      "metadata": {
        "id": "54K9pHIKEcFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_names = list(waste_labels.keys())"
      ],
      "metadata": {
        "id": "DwcD9GzUD6yk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred, target_names = target_names))"
      ],
      "metadata": {
        "id": "d6lLg2p6FJ7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix\n",
        "\n",
        "cm = confusion_matrix(y_test, y pred)\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "\n",
        "  if normalize:\n",
        "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "  plt.figure(figsize=(8, 6))\n",
        "  plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "  plt.title(title)\n",
        "  plt.colorbar()\n",
        "  tick_marks = np.arange(len(classes))\n",
        "  plt.xticks(tick_marks, classes, rotation=45)\n",
        "  plt.yticks(tick_marks, classes)\n",
        "  fmt = '.2f' if normalize else 'd'\n",
        "  thresh = cm.max() / 2.\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    plt.text(j, i, format(cm[i, j], fmt),\n",
        "              horizontalalignment=\"center\",\n",
        "              color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "  plt.tight_layout()\n",
        "  plt.ylabel('True label', fontweight=\"bold\")\n",
        "  plt.xlabel('Predicted label', fontweight=\"bold\")"
      ],
      "metadata": {
        "id": "Ev62w11vF7Fz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(cm, waste_labels.keys(),\n",
        "                      title = 'Confusion Matrix',\n",
        "                      cmap = plt.cm.OrRd)"
      ],
      "metadata": {
        "id": "GmAkAgxIHW9I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}